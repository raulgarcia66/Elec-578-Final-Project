{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_neural_network"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These files are the source code for the functions\n",
    "include(\"./RG_functions.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "solve_LR_coef(X,y,b; LIMIT)\n",
    "\n",
    "Logistic Regression\n",
    "Computes parameters b for logistic regression using the Newton-Rhapson Algorithm.\n",
    "X must have 1's appended as first column. y must have 1,0 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data that is approximately linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rand(500,2)\n",
    "y = zeros(500)\n",
    "pos_ind = []\n",
    "neg_ind = []\n",
    "for i=1:size(X,1)\n",
    "    if X[i,2] > 1.5*X[i,1] - .25\n",
    "        y[i] = 1\n",
    "        push!(pos_ind,i)\n",
    "    else\n",
    "        y[i] = 0\n",
    "        push!(neg_ind,i)\n",
    "    end\n",
    "end\n",
    "\n",
    "#class_pos = X[pos_ind,:]\n",
    "#class_neg = X[neg_ind,:]\n",
    "\n",
    "#scatter(class_pos[:,1], class_pos[:,2], color=\"blue\", label=\"Class 1\")\n",
    "#scatter!(class_neg[:,1], class_neg[:,2], color=\"red\", label=\"Class 2\")\n",
    "\n",
    "#x = LinRange(0,1,100)\n",
    "f(x) = 1.5*x - .25\n",
    "#plot!(x, f.(x),xlims=(0,1),ylims=(0,1))\n",
    "\n",
    "x = LinRange(1/5,4/5,10)\n",
    "x_noise_class1 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "x_noise_class2 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "#scatter!(x, x_noise_class1, color=\"blue\")\n",
    "#scatter!(x, x_noise_class2, color=\"red\")\n",
    "Xx = vcat(X,hcat(x,x_noise_class1), hcat(x,x_noise_class2))\n",
    "X = hcat(ones(size(Xx,1),1),Xx)   # append columns of 1's\n",
    "y = vcat(y,ones(10),zeros(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve for parameters and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pred (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve\n",
    "n,p = size(X)\n",
    "b = zeros(p)\n",
    "b = solve_LR_coef(X,y,b)\n",
    "# Report error\n",
    "prob(x, β) = 1 / (1 + exp(-(dot(x,β) )))\n",
    "\n",
    "# Prediction function\n",
    "pred(x,b) = round(prob(x,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 520 training observations misclassified.\n"
     ]
    }
   ],
   "source": [
    "misclass = 0\n",
    "for i = 1:n\n",
    "    if pred(X[i,:],b) == y[i]\n",
    "        misclass += 1\n",
    "    end\n",
    "end\n",
    "println(\"$misclass out of $n training observations misclassified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kernel_ridge(X,y,λ,K)\n",
    "\n",
    "Kernel Ridge Regression\n",
    "Computes parameters α for the kernel ridge estimator with kernel function K and hyperparameter λ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())\n",
    "n,p = size(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters for two different basis functions and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_kernel_ridge (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Radial Basis Function\n",
    "s = 10\n",
    "K_rbf(x,z) = exp(-(norm(x-z)^2) / (2*(s^2)))\n",
    "# Polynomial Basis Function\n",
    "c = 1; d = 2\n",
    "K_poly(x,z) = (c + dot(x,z))^d\n",
    "\n",
    "λ = 1\n",
    "α_rbf = kernel_ridge(X,y,λ,K_rbf)\n",
    "α_poly = kernel_ridge(X,y,λ,K_poly)\n",
    "\n",
    "# Prediction function\n",
    "pred_kernel_ridge(x,K,X,α) = sum( K(x,X[i,:]) * α[i] for i = 1:size(X,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report mean squared error for each basis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error with RBF kernel: 48.58030241248382\n",
      "Mean square error with polynomial kernel: 6.363275739611623\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "y_preds_rbf = zeros(n)\n",
    "y_preds_poly = zeros(n)\n",
    "for i = 1:n\n",
    "    y_preds_rbf[i] = pred_kernel_ridge(X[i,:],K_rbf,X,α_rbf)\n",
    "    y_preds_poly[i] = pred_kernel_ridge(X[i,:],K_poly,X,α_poly)\n",
    "end\n",
    "println(\"Mean square error with RBF kernel: $(Statistics.mean( (y_preds_rbf .- y).^2))\")\n",
    "println(\"Mean square error with polynomial kernel: $(Statistics.mean( (y_preds_poly .- y).^2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximal Gradient Descent"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prox_grad_desc(X,y,β,λ; LIMIT)\n",
    "\n",
    "Proximal Gradient Descent\n",
    "Computes parameters β given initial guess for least squares regression with ℓ-1 penalty.\n",
    "Has hyperparameter λ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for regression and center it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())\n",
    "n,p = size(X)\n",
    "# Center y and estimate β_0\n",
    "y_centered = y .- Statistics.mean(y)\n",
    "β_0 = Statistics.mean(y)\n",
    "# Create matrix of centered X columns\n",
    "X_centered = zeros(n,p)\n",
    "for j in 1:p\n",
    "    X_centered[:,j] = X[:,j] .- Statistics.mean(X[:,j])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1000.\n",
      "Max iterations reached.\n",
      "Real[0; 0.0381765577924749; 0; 0; 0; 0; 0; 0; 0; -0.016327374889328842; 0; 0.010874369828524572; -0.1857394401823319]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pred (generic function with 2 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize β\n",
    "β_init = zeros(size(X_centered,2))\n",
    "λ = 10000\n",
    "\n",
    "β = prox_grad_desc(X_centered, y_centered, β_init, λ)\n",
    "println(\"$β\")\n",
    "\n",
    "# Prediction function\n",
    "pred(X,β,β_0) = β_0 .+ X * β"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 74.18408330593503\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred(X,β,β_0)\n",
    "\n",
    "MSE = Statistics.mean((y - y_pred).^2)\n",
    "println(\"Mean squared error: $MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "elastic_net(X,y,β,λ,α; LIMIT)\n",
    "\n",
    "Elastic Net\n",
    "Computes parameters β given initial guess for least squares regression with elastic net penalty.\n",
    "Uses soft-thresholding function update derived in Homework 2. Hyperparameters are λ and α."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for regression and center it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())\n",
    "n,p = size(X)\n",
    "# Center y and estimate β_0\n",
    "y_centered = y .- Statistics.mean(y)\n",
    "β_0 = Statistics.mean(y)\n",
    "# Create matrix of centered X columns\n",
    "X_centered = zeros(n,p)\n",
    "for j in 1:p\n",
    "    X_centered[:,j] = X[:,j] .- Statistics.mean(X[:,j])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1000.\n",
      "Max iterations reached.\n",
      "Real[-0.041753603120333466; 0.05502475975765802; -0.019075219745038403; 0; 0; 0.015521427968780603; 0.0007620910771608188; -0.009899700036271004; 0.03733115888685481; -0.012845543597233947; -0.04954615426492346; 0.010518427530508552; -0.32525422243992397]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pred (generic function with 2 methods)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize β\n",
    "β_init = zeros(size(X_centered,2))\n",
    "λ = 10000\n",
    "α = 0.1   # 1 means lasso, 0 means ridge\n",
    "\n",
    "β = elastic_net(X_centered, y_centered, β_init, λ, α)\n",
    "println(\"$β\")\n",
    "\n",
    "# Prediction function\n",
    "pred(X,β,β_0) = β_0 .+ X * β"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 78.37089939829339\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred(X,β,β_0)\n",
    "\n",
    "MSE = Statistics.mean((y - y_pred).^2)\n",
    "println(\"Mean squared error: $MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Linear) Support Vector Machines"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SVM(X,y,C)\n",
    "\n",
    "Support Vector Machines\n",
    "Computes parameters β_0, β and the margins ξ for linear SVMs. Uses Gurobi to solve the\n",
    "optimization problem. Has hyperparameter C. y must have -1,1 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data that is approximately linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear boundary data\n",
    "X = rand(500,2)\n",
    "y = zeros(500)\n",
    "pos_ind = []\n",
    "neg_ind = []\n",
    "for i=1:size(X,1)\n",
    "    if X[i,2] > 1.5*X[i,1] - .25\n",
    "        y[i] = 1\n",
    "        push!(pos_ind,i)\n",
    "    else\n",
    "        y[i] = -1\n",
    "        push!(neg_ind,i)\n",
    "    end\n",
    "end\n",
    "\n",
    "#class_pos = X[pos_ind,:]\n",
    "#class_neg = X[neg_ind,:]\n",
    "\n",
    "#scatter(class_pos[:,1], class_pos[:,2], color=\"blue\", label=\"Class 1\")\n",
    "#scatter!(class_neg[:,1], class_neg[:,2], color=\"red\", label=\"Class 2\")\n",
    "\n",
    "#x = LinRange(0,1,100)\n",
    "f(x) = 1.5*x - .25\n",
    "#plot!(x, f.(x),xlims=(0,1),ylims=(0,1))\n",
    "\n",
    "x = LinRange(1/5,4/5,10)\n",
    "x_noise_class1 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "x_noise_class2 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "#scatter!(x, x_noise_class1, color=\"blue\")\n",
    "#scatter!(x, x_noise_class2, color=\"red\")\n",
    "Xx = vcat(X,hcat(x,x_noise_class1), hcat(x,x_noise_class2))\n",
    "X = hcat(ones(size(Xx,1),1),Xx)   # append columns of 1's\n",
    "y = vcat(y,ones(10),-ones(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-08-24\r\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\r\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\r\n",
      "Optimize a model with 521 rows, 524 columns and 3120 nonzeros\r\n",
      "Model fingerprint: 0x58800b31\r\n",
      "Model has 3 quadratic objective terms\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [3e-04, 1e+00]\r\n",
      "  Objective range  [0e+00, 0e+00]\r\n",
      "  QObjective range [2e+00, 2e+00]\r\n",
      "  Bounds range     [0e+00, 0e+00]\r\n",
      "  RHS range        [1e+00, 1e+02]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 521 rows, 524 columns, 3120 nonzeros\r\n",
      "Presolved model has 3 quadratic objective terms\r\n",
      "Ordering time: 0.00s\r\n",
      "\r\n",
      "Barrier statistics:\r\n",
      " Dense cols : 4\r\n",
      " Free vars  : 4\r\n",
      " AA' NZ     : 2.600e+03\r\n",
      " Factor NZ  : 3.513e+03\r\n",
      " Factor Ops : 3.024e+04 (less than 1 second per iteration)\r\n",
      " Threads    : 1\r\n",
      "\r\n",
      "                  Objective                Residual\r\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\r\n",
      "   0   5.63345561e-10 -5.63345561e-10  5.20e+05 1.82e-05  9.99e+05     0s\r\n",
      "   1   4.69886870e+06 -4.69342125e+06  1.61e+05 3.07e+02  3.22e+05     0s\r\n",
      "   2   7.78687431e+06 -7.81967346e+06  8.19e+03 1.22e+01  3.01e+04     0s\r\n",
      "   3   1.97335652e+06 -2.06591890e+06  1.01e+03 3.52e-08  5.72e+03     0s\r\n",
      "   4   8.23636152e+05 -9.72921664e+05  3.94e+02 1.38e-08  2.62e+03     0s\r\n",
      "   5   4.33513658e+05 -6.17233092e+05  2.25e+02 7.96e-09  1.59e+03     0s\r\n",
      "   6   1.72767342e+05 -3.78698692e+05  1.01e+02 3.80e-09  8.05e+02     0s\r\n",
      "   7   1.03364608e+05 -2.97509433e+05  6.51e+01 2.55e-09  5.54e+02     0s\r\n",
      "   8   2.46372954e+04 -1.90763759e+05  7.51e+00 4.28e-10  2.24e+02     0s\r\n",
      "   9   1.79204597e+04 -8.81255114e+04  2.93e+00 9.83e-10  1.05e+02     0s\r\n",
      "  10   1.01235914e+04 -3.25952189e+04  5.82e-01 8.34e-10  4.13e+01     0s\r\n",
      "  11   5.16962441e+03 -1.70909146e+04  2.10e-01 3.62e-10  2.14e+01     0s\r\n",
      "  12   3.49648378e+03 -1.02063291e+04  1.12e-01 2.10e-10  1.32e+01     0s\r\n",
      "  13   1.54283208e+03 -4.66299894e+03  1.62e-02 3.38e-11  5.97e+00     0s\r\n",
      "  14   8.07361691e+02 -1.92754315e+03  4.13e-03 3.10e-11  2.63e+00     0s\r\n",
      "  15   3.80888035e+02 -5.99072720e+02  7.17e-04 2.14e-12  9.42e-01     0s\r\n",
      "  16   2.62972878e+02 -2.96052313e+02  2.83e-04 1.46e-12  5.38e-01     0s\r\n",
      "  17   1.97167180e+02 -1.32369402e+02  1.48e-04 6.44e-13  3.17e-01     0s\r\n",
      "  18   1.51955884e+02 -4.74779788e+01  7.81e-05 5.49e-13  1.92e-01     0s\r\n",
      "  19   1.24854482e+02  2.27060607e+00  3.84e-05 2.43e-13  1.18e-01     0s\r\n",
      "  20   1.08181883e+02  2.93589601e+01  2.39e-05 1.32e-13  7.58e-02     0s\r\n",
      "  21   9.86966001e+01  4.25566121e+01  1.67e-05 1.21e-13  5.40e-02     0s\r\n",
      "  22   8.99333829e+01  5.33223190e+01  8.89e-06 6.75e-14  3.52e-02     0s\r\n",
      "  23   8.22166136e+01  6.13935743e+01  4.04e-06 6.48e-14  2.00e-02     0s\r\n",
      "  24   7.86491384e+01  6.48527427e+01  1.60e-06 3.77e-14  1.33e-02     0s\r\n",
      "  25   7.69561894e+01  6.73119765e+01  8.32e-07 4.44e-14  9.27e-03     0s\r\n",
      "  26   7.47295353e+01  6.97070060e+01  4.17e-07 1.69e-14  4.83e-03     0s\r\n",
      "  27   7.29915436e+01  7.14842793e+01  3.04e-09 2.53e-14  1.45e-03     0s\r\n",
      "  28   7.25444087e+01  7.19452595e+01  8.52e-10 2.84e-14  5.76e-04     0s\r\n",
      "  29   7.22856440e+01  7.22015205e+01  7.82e-13 2.80e-14  8.09e-05     0s\r\n",
      "  30   7.22441670e+01  7.22438865e+01  1.51e-12 6.22e-15  2.70e-07     0s\r\n",
      "  31   7.22440586e+01  7.22440583e+01  1.28e-09 2.31e-14  2.79e-10     0s\r\n",
      "\r\n",
      "Barrier solved model in 31 iterations and 0.01 seconds\r\n",
      "Optimal objective 7.22440586e+01\r\n",
      "\r\n",
      "\r\n",
      "User-callback calls 105, time in user-callback 0.00 sec\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVM_classifier (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameter\n",
    "C = 100\n",
    "# Solve\n",
    "(β_0, β, ξ) = SVM(X,y,C)\n",
    "\n",
    "# Prediction function\n",
    "SVM_classifier(x,β_0,β) = sign(x'*β + β_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 out of 506 training observations misclassified.\n"
     ]
    }
   ],
   "source": [
    "# Report error\n",
    "misclass = 0\n",
    "for i = 1:n\n",
    "    if SVM_classifier(X[i,:], β_0, β) != y[i]\n",
    "        misclass += 1\n",
    "    end\n",
    "end\n",
    "println(\"$misclass out of $n training observations misclassified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Support Vector Machines"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kernel_SVM(X,y,C,K)\n",
    "\n",
    "Kernel Support Vector Machines\n",
    "Computers paramters α for Kernel SVMs with kernel function K and hyperparameter C. Uses Gurobi\n",
    "to solve the optimization problem. y must have -1,1 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data that is approximately separable with a quadratic boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic Boundary Data\n",
    "X = rand(500,2)\n",
    "y = zeros(500)\n",
    "pos_ind = []\n",
    "neg_ind = []\n",
    "for i=1:size(X,1)\n",
    "    if X[i,2] > -(X[i,1]+.5)*(X[i,1]-1)\n",
    "        y[i] = 1\n",
    "        push!(pos_ind,i)\n",
    "    else\n",
    "        y[i] = -1\n",
    "        push!(neg_ind,i)\n",
    "    end\n",
    "end\n",
    "\n",
    "#class_pos = X[pos_ind,:]\n",
    "#class_neg = X[neg_ind,:]\n",
    "\n",
    "#scatter(class_pos[:,1], class_pos[:,2], color=\"blue\", label=\"Class 1\")\n",
    "#scatter!(class_neg[:,1], class_neg[:,2], color=\"red\", label=\"Class 2\")\n",
    "\n",
    "#x = LinRange(0,1,100)\n",
    "f(x) = -(x+0.5)*(x-1)\n",
    "#plot!(x, f.(x),xlims=(0,1),ylims=(0,1))\n",
    "\n",
    "x = LinRange(0,1,10)\n",
    "x_noise_class1 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "x_noise_class2 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "#scatter!(x, x_noise_class1, color=\"blue\")\n",
    "#scatter!(x, x_noise_class2, color=\"red\")\n",
    "X = vcat(X,hcat(x,x_noise_class1), hcat(x,x_noise_class2))\n",
    "y = vcat(y,ones(10),-ones(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters for two different basis functions and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-08-24\r\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\r\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\r\n",
      "Optimize a model with 1 rows, 520 columns and 520 nonzeros\r\n",
      "Model fingerprint: 0x53189ea5\r\n",
      "Model has 135460 quadratic objective terms\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e+00, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  QObjective range [1e+00, 2e+00]\r\n",
      "  Bounds range     [1e+01, 1e+01]\r\n",
      "  RHS range        [0e+00, 0e+00]\r\n",
      "Presolve time: 0.01s\r\n",
      "Presolved: 1 rows, 520 columns, 520 nonzeros\r\n",
      "Presolved model has 135460 quadratic objective terms\r\n",
      "Ordering time: 0.00s\r\n",
      "\r\n",
      "Barrier statistics:\r\n",
      " Free vars  : 6\r\n",
      " AA' NZ     : 2.100e+01\r\n",
      " Factor NZ  : 2.800e+01\r\n",
      " Factor Ops : 1.400e+02 (less than 1 second per iteration)\r\n",
      " Threads    : 1\r\n",
      "\r\n",
      "                  Objective                Residual\r\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\r\n",
      "   0   2.08086002e+06  1.30260000e+06  6.00e+04 1.70e-03  1.00e+06     0s\r\n",
      "   1   2.54957334e+03  1.29929410e+06  6.00e-02 1.70e-09  1.25e+03     0s\r\n",
      "   2   2.56100691e+03  6.35677518e+03  8.84e-05 2.51e-12  3.65e+00     0s\r\n",
      "   3   4.53611166e+03  5.00161941e+03  1.38e-06 3.90e-14  4.48e-01     0s\r\n",
      "   4   4.53953639e+03  4.57854119e+03  8.82e-08 2.66e-15  3.75e-02     0s\r\n",
      "   5   4.54210056e+03  4.57549988e+03  6.80e-08 2.66e-15  3.21e-02     0s\r\n",
      "   6   4.54616343e+03  4.56562536e+03  3.85e-08 2.66e-15  1.87e-02     0s\r\n",
      "   7   4.54950025e+03  4.56130245e+03  1.96e-08 2.66e-15  1.13e-02     0s\r\n",
      "   8   4.55239340e+03  4.55796655e+03  8.83e-09 2.66e-15  5.36e-03     0s\r\n",
      "   9   4.55381881e+03  4.55680632e+03  4.49e-09 1.78e-15  2.87e-03     0s\r\n",
      "  10   4.55448799e+03  4.55630563e+03  2.48e-09 1.78e-15  1.75e-03     0s\r\n",
      "  11   4.55493531e+03  4.55598460e+03  1.39e-09 1.78e-15  1.01e-03     0s\r\n",
      "  12   4.55513617e+03  4.55585851e+03  8.63e-10 2.66e-15  6.95e-04     0s\r\n",
      "  13   4.55533074e+03  4.55572268e+03  4.50e-10 1.78e-15  3.77e-04     0s\r\n",
      "  14   4.55550069e+03  4.55561042e+03  9.61e-11 2.66e-15  1.06e-04     0s\r\n",
      "  15   4.55554953e+03  4.55557678e+03  1.49e-11 2.66e-15  2.62e-05     0s\r\n",
      "  16   4.55556448e+03  4.55556456e+03  1.15e-14 2.66e-15  7.76e-08     0s\r\n",
      "  17   4.55556452e+03  4.55556452e+03  9.77e-15 3.55e-15  7.77e-11     0s\r\n",
      "\r\n",
      "Barrier solved model in 17 iterations and 0.03 seconds\r\n",
      "Optimal objective 4.55556452e+03\r\n",
      "\r\n",
      "\r\n",
      "User-callback calls 79, time in user-callback 0.00 sec\r\n",
      "Academic license - for non-commercial use only - expires 2022-08-24\r\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\r\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\r\n",
      "Optimize a model with 1 rows, 520 columns and 520 nonzeros\r\n",
      "Model fingerprint: 0xdb76f3f8\r\n",
      "Model has 135460 quadratic objective terms\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e+00, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  QObjective range [4e-09, 7e+00]\r\n",
      "  Bounds range     [1e+01, 1e+01]\r\n",
      "  RHS range        [0e+00, 0e+00]\r\n",
      "Presolve time: 0.01s\r\n",
      "Presolved: 1 rows, 520 columns, 520 nonzeros\r\n",
      "Presolved model has 135460 quadratic objective terms\r\n",
      "Ordering time: 0.00s\r\n",
      "\r\n",
      "Barrier statistics:\r\n",
      " Free vars  : 3\r\n",
      " AA' NZ     : 6.000e+00\r\n",
      " Factor NZ  : 1.000e+01\r\n",
      " Factor Ops : 3.000e+01 (less than 1 second per iteration)\r\n",
      " Threads    : 1\r\n",
      "\r\n",
      "                  Objective                Residual\r\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\r\n",
      "   0   1.42944884e+06  2.62260000e+06  1.06e+05 1.34e-06  1.00e+06     0s\r\n",
      "   1   5.55657591e+03  2.59216571e+06  3.90e+02 4.93e-09  6.15e+03     0s\r\n",
      "   2  -5.39087928e+04  7.65363454e+05  3.90e-04 5.68e-13  7.88e+02     0s\r\n",
      "   3  -1.29696972e+04  4.16294649e+04  1.48e-05 3.69e-13  5.25e+01     0s\r\n",
      "   4  -1.62563029e+03  5.11774580e+03  1.95e-07 9.59e-14  6.48e+00     0s\r\n",
      "   5  -3.68302113e+02  2.80228777e+03  7.64e-08 4.82e-14  3.05e+00     0s\r\n",
      "   6   1.48364089e+02  1.75120225e+03  3.03e-08 1.78e-14  1.54e+00     0s\r\n",
      "   7   4.01786834e+02  1.28810605e+03  1.34e-08 1.42e-14  8.52e-01     0s\r\n",
      "   8   5.17545630e+02  1.08093332e+03  7.51e-09 1.25e-14  5.42e-01     0s\r\n",
      "   9   5.95280082e+02  9.67778254e+02  4.27e-09 7.66e-15  3.58e-01     0s\r\n",
      "  10   6.56154600e+02  8.82587030e+02  2.52e-09 7.92e-15  2.18e-01     0s\r\n",
      "  11   6.89576957e+02  8.47061341e+02  1.55e-09 4.63e-15  1.51e-01     0s\r\n",
      "  12   7.11936535e+02  8.25157012e+02  9.81e-10 6.36e-15  1.09e-01     0s\r\n",
      "  13   7.35723020e+02  8.05210728e+02  1.74e-10 6.15e-15  6.68e-02     0s\r\n",
      "  14   7.53366753e+02  7.84096314e+02  5.00e-11 7.70e-15  2.95e-02     0s\r\n",
      "  15   7.65844371e+02  7.70880932e+02  3.91e-14 7.54e-15  4.84e-03     0s\r\n",
      "  16   7.67884246e+02  7.68772357e+02  2.53e-14 6.66e-15  8.54e-04     0s\r\n",
      "  17   7.68299118e+02  7.68348555e+02  3.15e-14 8.09e-15  4.75e-05     0s\r\n",
      "  18   7.68323464e+02  7.68323635e+02  1.67e-13 6.89e-15  1.64e-07     0s\r\n",
      "  19   7.68323545e+02  7.68323546e+02  2.10e-12 6.03e-15  1.64e-10     0s\r\n",
      "\r\n",
      "Barrier solved model in 19 iterations and 0.02 seconds\r\n",
      "Optimal objective 7.68323545e+02\r\n",
      "\r\n",
      "\r\n",
      "User-callback calls 82, time in user-callback 0.00 sec\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "kernel_SVM_classifier (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Radial Basis Function\n",
    "s = 100\n",
    "K_rbf(x,z) = exp(-(norm(x-z)^2) / (2*(s^2)))\n",
    "# Polynomial Basis Function\n",
    "c = 0; d = 2\n",
    "K_poly(x,z) = (c + dot(x,z))^d\n",
    "\n",
    "C = 10\n",
    "α_rbf = kernel_SVM(X,y,C,K_rbf)\n",
    "α_poly = kernel_SVM(X,y,C,K_poly)\n",
    "\n",
    "# find index of max α component, let that be k \n",
    "k_rbf = argmax(α_rbf)\n",
    "k_poly = argmax(α_poly)\n",
    "\n",
    "b_rbf = y[k_rbf] - sum( α_rbf[i]*y[i]*K_rbf(X[k_rbf,:],X[i,:]) for i = 1:n)\n",
    "b_poly = y[k_poly] - sum( α_poly[i]*y[i]*K_poly(X[k_poly,:],X[i,:]) for i = 1:n)\n",
    "\n",
    "# Prediction function\n",
    "kernel_SVM_classifier(x,K,X,α,b) = sign(sum( α[i]*y[i]*K(x,X[i,:]) for i = 1:size(X,1)) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF kernel: 286 out of 506 training observations misclassified.\n",
      "Polynomial kernel: 33 out of 506 training observations misclassified.\n"
     ]
    }
   ],
   "source": [
    "misclass_rbf = 0\n",
    "misclass_poly = 0\n",
    "for i = 1:n\n",
    "    if kernel_SVM_classifier(X[i,:], K_rbf,X, α_rbf, b_rbf) != y[i]\n",
    "        misclass_rbf += 1\n",
    "    end\n",
    "    if kernel_SVM_classifier(X[i,:], K_poly,X, α_poly, b_poly) != y[i]\n",
    "        misclass_poly += 1\n",
    "    end\n",
    "end\n",
    "println(\"RBF kernel: $misclass_rbf out of $n training observations misclassified.\")\n",
    "println(\"Polynomial kernel: $misclass_poly out of $n training observations misclassified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Procedure"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bootstrapper(X,y,B)\n",
    "\n",
    "Boostrapping Procedure\n",
    "Returns B bootstrapped samples of input data X and y. Samples are stored in an array. The\n",
    "indices used and not used in each sample are also returned for out-of-bag error calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1 = [3.0 3.0 3.0 3.0 3.0; 4.0 4.0 4.0 4.0 4.0; 3.0 3.0 3.0 3.0 3.0; 2.0 2.0 2.0 2.0 2.0]\n",
      "y_1 = [3.0, 4.0, 3.0, 2.0]\n",
      "Indices used: Set(Any[4, 2, 3])\n",
      "Indices not used: Set([1])\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "X = [ones(5)'; 2*ones(5)'; 3*ones(5)'; 4*ones(5)']\n",
    "y = [1.0; 2.0; 3.0; 4.0]\n",
    "# Number of boostrapp samples\n",
    "B = 10\n",
    "\n",
    "b_samples, ind_used, ind_not_used = bootstrapper(X,y,B)\n",
    "\n",
    "# Observations and indices for the i-th bootstrapped sample\n",
    "i = 1\n",
    "X_b, y_b = b_samples[i]\n",
    "println(\"X_$i = $X_b\\ny_$i = $y_b\")\n",
    "println(\"Indices used: $(ind_used[i])\")\n",
    "println(\"Indices not used: $(ind_not_used[i])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_neural_network(X,y,num_hidden_layers,size_hidden_layers;h,activation,problem_type,num_classes,num_epochs)\n",
    "\n",
    "Initiate Neural Network\n",
    "Computes weight matrices W and biases b and prints the training error. W and b are initialized in this\n",
    "function. Activation options are 'sigmoid' and 'ReLu'. Problem types are 'classification' and 'regression'.\n",
    "Other parameters settings are number of hidden layers, number of neurons per hidden layer, number of epochs,\n",
    "number of classes (1 if regression), and learning rate h."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "update_neural_network(X,y,W,b,num_hidden_layers,size_hidden_layers;h,activation,problem_type,num_classes,num_epochs)\n",
    "\n",
    "Update Neural Network\n",
    "Computes weight matrices W and biases b and prints the training error. W and b are passed as arguments in this\n",
    "function. The network settings should be the same as those passed when creating W and b."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict_neural_network(X,W,b,num_hidden_layers,size_hidden_layers;activation,problem_type,num_classes)\n",
    "\n",
    "Predictions via Trained Neural Network\n",
    "Computes predictions to input data X given weights W and biases b. Network settings should be the same\n",
    "as those which were used to learn W and b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST handwritten digit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classication\n",
    "\n",
    "# load partial training set\n",
    "tr_size = 5000\n",
    "train_x, train_y = MNIST.traindata(1:tr_size)\n",
    "# load partial test set\n",
    "te_size = 200\n",
    "test_x,  test_y  = MNIST.testdata(1:te_size)\n",
    "\n",
    "X = zeros(tr_size,784)\n",
    "for i = 1:tr_size\n",
    "    X[i,:] = reshape(train_x[:,:,i],1,784)\n",
    "end\n",
    "y = train_y[1:tr_size]\n",
    "\n",
    "X_test = zeros(te_size,784)\n",
    "for i = 1:te_size\n",
    "    X_test[i,:] = reshape(test_x[:,:,i],1,784)\n",
    "end\n",
    "y_test = test_y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n",
      "Total loss is 21194.91070211043.\n",
      "Average loss 4.2389821404220855 out of 5000 training images.\n",
      "4499 of 5000 training images misclassified.\n"
     ]
    }
   ],
   "source": [
    "num_hidden_layers = 2\n",
    "size_hidden_layers = 8\n",
    "W,b = train_neural_network(X,y,num_hidden_layers,size_hidden_layers,activation=\"sigmoid\",problem_type=\"classification\",num_classes=10,num_epochs=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n",
      "Total loss is 21194.91070211043.\n",
      "Average loss 4.2389821404220855 out of 5000 training images.\n",
      "4499 of 5000 training images misclassified.\n"
     ]
    }
   ],
   "source": [
    "W,b = update_neural_network(X,y,W,b,num_hidden_layers,size_hidden_layers,activation=\"sigmoid\",problem_type=\"classification\",num_classes=10,num_epochs=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200-element Vector{Float64}:\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " ⋮\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_neural_network(X_test,W,b,num_hidden_layers,size_hidden_layers;activation=\"sigmoid\",problem_type=\"classification\",num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "X_all = transpose(BostonHousing.features())\n",
    "X = X_all[1:450,:]\n",
    "X_test = X_all[451:end,:]\n",
    "y_all = transpose(BostonHousing.targets())\n",
    "y = y_all[1:450]\n",
    "y_test = y_all[451:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n",
      "Average loss 185.64078020187634 out of 450 training images.\n"
     ]
    }
   ],
   "source": [
    "num_hidden_layers = 2\n",
    "size_hidden_layers = 10\n",
    "W,b = train_neural_network(X,y,num_hidden_layers,size_hidden_layers,activation=\"sigmoid\",problem_type=\"regression\",num_epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n",
      "Average loss 185.64064165738674 out of 450 training images.\n"
     ]
    }
   ],
   "source": [
    "W,b = update_neural_network(X,y,W,b,num_hidden_layers,size_hidden_layers,activation=\"sigmoid\",problem_type=\"regression\",num_epochs=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56-element Vector{Float64}:\n",
       " 13.278975477497077\n",
       " 13.279015575160738\n",
       " 13.279015527074977\n",
       " 13.279016382274545\n",
       " 13.279016480147035\n",
       " 13.279015840552347\n",
       " 13.27901649174759\n",
       " 13.279015408827094\n",
       " 13.279017876734613\n",
       " 13.27901752947357\n",
       " 13.279016737502179\n",
       " 13.27901580641361\n",
       " 13.27901763328099\n",
       "  ⋮\n",
       " 13.278992190013174\n",
       " 13.278993128541625\n",
       " 13.278994509817132\n",
       " 13.27899478303203\n",
       " 13.278991849815988\n",
       " 13.278990830545688\n",
       " 13.278992219548739\n",
       " 13.278977439258489\n",
       " 13.278975685271032\n",
       " 13.278974566841047\n",
       " 13.278977337403289\n",
       " 13.278977249551858"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_neural_network(X_test,W,b,num_hidden_layers,size_hidden_layers;activation=\"sigmoid\",problem_type=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
