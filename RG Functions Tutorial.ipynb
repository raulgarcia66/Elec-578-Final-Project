{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia is a high-level, high-performance programming language for scientific computing. Its machine learning libraries are not as expansive or developed as Python yet, hence for my final project I implemented various machine learning methods in Julia and demonstrate their usage in this notebook. Below each function, I describe the method it performs and the details of its input arguments. Most methods solve for parameters of a model, thus prediction functions are generated afterwards corresponding to the learned parameters. Lastly, the hyperparameters I use here are mostly random and can be tuned for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GitHub repository is: https://github.com/raulgarcia66/Elec-578-Final-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the source code for the functions\n",
    "include(\"./RG_functions.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "solve_LR_coef(X,y,b; LIMIT)\n",
    "\n",
    "Logistic Regression\n",
    "Computes parameters b for logistic regression using the Newton-Rhapson Algorithm.\n",
    "X must have 1's appended as first column. y must have 1,0 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data that is approximately linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rand(500,2)\n",
    "y = zeros(500)\n",
    "for i=1:size(X,1)\n",
    "    if X[i,2] > 1.5*X[i,1] - .25\n",
    "        y[i] = 1.0\n",
    "    else\n",
    "        y[i] = 0.0\n",
    "    end\n",
    "end\n",
    "\n",
    "f(x) = 1.5*x - .25\n",
    "\n",
    "x = LinRange(1/5,4/5,10)\n",
    "x_noise_class1 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "x_noise_class2 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "Xx = vcat(X,hcat(x,x_noise_class1), hcat(x,x_noise_class2))\n",
    "X = hcat(ones(size(Xx,1),1),Xx)   # append columns of 1's\n",
    "y = vcat(y,ones(10),zeros(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve for parameters and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 7.\n"
     ]
    }
   ],
   "source": [
    "n,p = size(X)\n",
    "b = zeros(p)\n",
    "b = solve_LR_coef(X,y,b)\n",
    "prob(x, β) = 1 / (1 + exp(-(dot(x,β) )))\n",
    "\n",
    "# Prediction function\n",
    "pred(x,b) = round(prob(x,b));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520 out of 520 training observations misclassified.\n"
     ]
    }
   ],
   "source": [
    "misclass = 0\n",
    "for i = 1:n\n",
    "    if pred(X[i,:],b) != y[i]\n",
    "        misclass += 1\n",
    "    end\n",
    "end\n",
    "println(\"$misclass out of $n training observations misclassified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kernel_ridge(X,y,λ,K)\n",
    "\n",
    "Kernel Ridge Regression\n",
    "Computes parameters α for the kernel ridge estimator with kernel function K and hyperparameter λ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())\n",
    "n,p = size(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters for two different basis functions and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radial Basis Function\n",
    "s = 10\n",
    "K_rbf(x,z) = exp(-(norm(x-z)^2) / (2*(s^2)))\n",
    "# Polynomial Basis Function\n",
    "c = 1; d = 2\n",
    "K_poly(x,z) = (c + dot(x,z))^d\n",
    "\n",
    "λ = 1\n",
    "α_rbf = kernel_ridge(X,y,λ,K_rbf)\n",
    "α_poly = kernel_ridge(X,y,λ,K_poly)\n",
    "\n",
    "# Prediction function\n",
    "pred_kernel_ridge(x,K,X,α) = sum( K(x,X[i,:]) * α[i] for i = 1:size(X,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report mean squared error for each basis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error with RBF kernel: 48.58030241248382\n",
      "Mean square error with polynomial kernel: 6.363275739611623\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "y_preds_rbf = zeros(n)\n",
    "y_preds_poly = zeros(n)\n",
    "for i = 1:n\n",
    "    y_preds_rbf[i] = pred_kernel_ridge(X[i,:],K_rbf,X,α_rbf)\n",
    "    y_preds_poly[i] = pred_kernel_ridge(X[i,:],K_poly,X,α_poly)\n",
    "end\n",
    "println(\"Mean square error with RBF kernel: $(Statistics.mean( (y_preds_rbf .- y).^2))\")\n",
    "println(\"Mean square error with polynomial kernel: $(Statistics.mean( (y_preds_poly .- y).^2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximal Gradient Descent"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prox_grad_desc(X,y,β,λ; LIMIT)\n",
    "\n",
    "Proximal Gradient Descent\n",
    "Computes parameters β given initial guess for least squares regression with ℓ-1 penalty.\n",
    "Has hyperparameter λ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for regression and center it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())\n",
    "n,p = size(X)\n",
    "# Center y and estimate β_0\n",
    "y_centered = y .- Statistics.mean(y)\n",
    "β_0 = Statistics.mean(y)\n",
    "# Create matrix of centered X columns\n",
    "X_centered = zeros(n,p)\n",
    "for j in 1:p\n",
    "    X_centered[:,j] = X[:,j] .- Statistics.mean(X[:,j])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1000.\n",
      "Max iterations reached.\n",
      "Real[0; 0.0381765577924749; 0; 0; 0; 0; 0; 0; 0; -0.016327374889328842; 0; 0.010874369828524572; -0.1857394401823319]\n"
     ]
    }
   ],
   "source": [
    "# Initialize β\n",
    "β_init = zeros(size(X_centered,2))\n",
    "λ = 10000\n",
    "\n",
    "β = prox_grad_desc(X_centered, y_centered, β_init, λ)\n",
    "println(\"$β\")\n",
    "\n",
    "# Prediction function\n",
    "pred(X,β,β_0) = β_0 .+ X * β;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 74.18408330593503\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred(X,β,β_0)\n",
    "\n",
    "MSE = Statistics.mean((y - y_pred).^2)\n",
    "println(\"Mean squared error: $MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "elastic_net(X,y,β,λ,α; LIMIT)\n",
    "\n",
    "Elastic Net\n",
    "Computes parameters β given initial guess for least squares regression with elastic net penalty.\n",
    "Uses soft-thresholding function update derived in Homework 2. Hyperparameters are λ and α."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for regression and center it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())\n",
    "n,p = size(X)\n",
    "# Center y and estimate β_0\n",
    "y_centered = y .- Statistics.mean(y)\n",
    "β_0 = Statistics.mean(y)\n",
    "# Create matrix of centered X columns\n",
    "X_centered = zeros(n,p)\n",
    "for j in 1:p\n",
    "    X_centered[:,j] = X[:,j] .- Statistics.mean(X[:,j])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1000.\n",
      "Max iterations reached.\n",
      "Real[-0.041753603120333466; 0.05502475975765802; -0.019075219745038403; 0; 0; 0.015521427968780603; 0.0007620910771608188; -0.009899700036271004; 0.03733115888685481; -0.012845543597233947; -0.04954615426492346; 0.010518427530508552; -0.32525422243992397]\n"
     ]
    }
   ],
   "source": [
    "# Initialize β\n",
    "β_init = zeros(size(X_centered,2))\n",
    "λ = 10000\n",
    "α = 0.1   # 1 means lasso, 0 means ridge\n",
    "\n",
    "β = elastic_net(X_centered, y_centered, β_init, λ, α)\n",
    "println(\"$β\")\n",
    "\n",
    "# Prediction function\n",
    "pred(X,β,β_0) = β_0 .+ X * β;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 78.37089939829339\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred(X,β,β_0)\n",
    "\n",
    "MSE = Statistics.mean((y - y_pred).^2)\n",
    "println(\"Mean squared error: $MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Linear) Support Vector Machines"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SVM(X,y,C)\n",
    "\n",
    "Support Vector Machines\n",
    "Computes parameters β_0, β and the margins ξ for linear SVMs. Uses Gurobi to solve the\n",
    "optimization problem. Has hyperparameter C. y must have -1,1 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data that is approximately linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear boundary data\n",
    "X = rand(500,2)\n",
    "y = zeros(500)\n",
    "for i=1:size(X,1)\n",
    "    if X[i,2] > 1.5*X[i,1] - .25\n",
    "        y[i] = 1\n",
    "    else\n",
    "        y[i] = -1\n",
    "    end\n",
    "end\n",
    "\n",
    "f(x) = 1.5*x - .25\n",
    "\n",
    "x = LinRange(1/5,4/5,10)\n",
    "x_noise_class1 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "x_noise_class2 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "Xx = vcat(X,hcat(x,x_noise_class1), hcat(x,x_noise_class2))\n",
    "X = hcat(ones(size(Xx,1),1),Xx)   # append columns of 1's\n",
    "y = vcat(y,ones(10),-ones(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-08-24\r\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\r\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\r\n",
      "Optimize a model with 521 rows, 524 columns and 3120 nonzeros\r\n",
      "Model fingerprint: 0xda89d0f5\r\n",
      "Model has 3 quadratic objective terms\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [2e-03, 1e+00]\r\n",
      "  Objective range  [0e+00, 0e+00]\r\n",
      "  QObjective range [2e+00, 2e+00]\r\n",
      "  Bounds range     [0e+00, 0e+00]\r\n",
      "  RHS range        [1e+00, 1e+02]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 521 rows, 524 columns, 3120 nonzeros\r\n",
      "Presolved model has 3 quadratic objective terms\r\n",
      "Ordering time: 0.00s\r\n",
      "\r\n",
      "Barrier statistics:\r\n",
      " Dense cols : 4\r\n",
      " Free vars  : 4\r\n",
      " AA' NZ     : 2.600e+03\r\n",
      " Factor NZ  : 3.513e+03\r\n",
      " Factor Ops : 3.024e+04 (less than 1 second per iteration)\r\n",
      " Threads    : 1\r\n",
      "\r\n",
      "                  Objective                Residual\r\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\r\n",
      "   0   6.75733361e-10 -6.75733361e-10  5.20e+05 2.40e-05  9.99e+05     0s\r\n",
      "   1   4.76560919e+06 -4.76338184e+06  1.63e+05 3.10e+02  3.25e+05     0s\r\n",
      "   2   8.37673916e+06 -8.41762118e+06  7.11e+03 9.50e+00  2.92e+04     0s\r\n",
      "   3   2.13291506e+06 -2.22586471e+06  6.73e+02 3.11e-08  5.37e+03     0s\r\n",
      "   4   7.00034555e+05 -8.95564821e+05  1.98e+02 9.14e-09  2.07e+03     0s\r\n",
      "   5   1.69505516e+05 -4.30578807e+05  4.62e+01 2.67e-09  7.27e+02     0s\r\n",
      "   6   5.77120568e+04 -1.16600339e+05  5.67e+00 8.85e-10  1.72e+02     0s\r\n",
      "   7   4.50695345e+04 -1.06904893e+05  4.48e+00 7.20e-10  1.50e+02     0s\r\n",
      "   8   1.94813853e+04 -4.92865212e+04  1.18e+00 1.91e-10  6.66e+01     0s\r\n",
      "   9   8.16442481e+03 -1.92590056e+04  2.18e-01 5.94e-11  2.64e+01     0s\r\n",
      "  10   5.00106634e+03 -1.15563921e+04  1.10e-01 3.11e-11  1.59e+01     0s\r\n",
      "  11   1.84614673e+03 -4.44910821e+03  2.18e-02 2.34e-11  6.05e+00     0s\r\n",
      "  12   7.29009692e+02 -1.50157176e+03  4.10e-03 4.32e-12  2.14e+00     0s\r\n",
      "  13   3.63375202e+02 -5.41608733e+02  1.16e-03 3.39e-12  8.70e-01     0s\r\n",
      "  14   1.97020352e+02 -2.26549880e+02  3.10e-04 1.80e-12  4.07e-01     0s\r\n",
      "  15   1.17345653e+02 -6.66984945e+01  7.05e-05 1.88e-13  1.77e-01     0s\r\n",
      "  16   8.79248816e+01 -1.20280772e+01  3.29e-05 2.16e-13  9.61e-02     0s\r\n",
      "  17   7.22677323e+01  1.33509420e+01  1.72e-05 1.59e-13  5.67e-02     0s\r\n",
      "  18   6.30054125e+01  2.73602390e+01  1.01e-05 8.99e-14  3.43e-02     0s\r\n",
      "  19   5.53136514e+01  3.62735447e+01  4.02e-06 1.29e-14  1.83e-02     0s\r\n",
      "  20   5.14597277e+01  4.03112094e+01  1.98e-06 1.93e-14  1.07e-02     0s\r\n",
      "  21   4.91054838e+01  4.30179629e+01  8.59e-07 5.33e-15  5.85e-03     0s\r\n",
      "  22   4.74162772e+01  4.49210812e+01  2.64e-07 1.38e-14  2.40e-03     0s\r\n",
      "  23   4.66637331e+01  4.57205427e+01  5.71e-08 5.88e-15  9.07e-04     0s\r\n",
      "  24   4.62947062e+01  4.61020599e+01  5.73e-09 8.88e-15  1.85e-04     0s\r\n",
      "  25   4.61992544e+01  4.61973003e+01  4.03e-11 5.88e-15  1.88e-06     0s\r\n",
      "  26   4.61983023e+01  4.61983003e+01  7.39e-13 4.44e-15  1.90e-09     0s\r\n",
      "  27   4.61983013e+01  4.61983013e+01  1.42e-13 2.66e-15  1.90e-12     0s\r\n",
      "\r\n",
      "Barrier solved model in 27 iterations and 0.01 seconds\r\n",
      "Optimal objective 4.61983013e+01\r\n",
      "\r\n",
      "\r\n",
      "User-callback calls 97, time in user-callback 0.00 sec\r\n"
     ]
    }
   ],
   "source": [
    "# Set parameter\n",
    "C = 100\n",
    "# Solve\n",
    "(β_0, β, ξ) = SVM(X,y,C)\n",
    "\n",
    "# Prediction function\n",
    "SVM_classifier(x,β_0,β) = sign(x'*β + β_0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 out of 506 training observations misclassified.\n"
     ]
    }
   ],
   "source": [
    "# Report error\n",
    "misclass = 0\n",
    "for i = 1:n\n",
    "    if SVM_classifier(X[i,:], β_0, β) != y[i]\n",
    "        misclass += 1\n",
    "    end\n",
    "end\n",
    "println(\"$misclass out of $n training observations misclassified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Support Vector Machines"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kernel_SVM(X,y,C,K)\n",
    "\n",
    "Kernel Support Vector Machines\n",
    "Computers paramters α for Kernel SVMs with kernel function K and hyperparameter C. Uses Gurobi\n",
    "to solve the optimization problem. y must have -1,1 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data that is approximately separable with a quadratic boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic Boundary Data\n",
    "X = rand(500,2)\n",
    "y = zeros(500)\n",
    "for i=1:size(X,1)\n",
    "    if X[i,2] > -(X[i,1]+.5)*(X[i,1]-1)\n",
    "        y[i] = 1\n",
    "    else\n",
    "        y[i] = -1\n",
    "    end\n",
    "end\n",
    "\n",
    "f(x) = -(x+0.5)*(x-1)\n",
    "\n",
    "x = LinRange(0,1,10)\n",
    "x_noise_class1 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "x_noise_class2 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "X = vcat(X,hcat(x,x_noise_class1), hcat(x,x_noise_class2))\n",
    "y = vcat(y,ones(10),-ones(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute parameters for two different basis functions and create prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-08-24\r\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\r\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\r\n",
      "Optimize a model with 1 rows, 520 columns and 520 nonzeros\r\n",
      "Model fingerprint: 0xb086e786\r\n",
      "Model has 135460 quadratic objective terms\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e+00, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  QObjective range [1e+00, 2e+00]\r\n",
      "  Bounds range     [1e+01, 1e+01]\r\n",
      "  RHS range        [0e+00, 0e+00]\r\n",
      "Presolve time: 0.01s\r\n",
      "Presolved: 1 rows, 520 columns, 520 nonzeros\r\n",
      "Presolved model has 135460 quadratic objective terms\r\n",
      "Ordering time: 0.00s\r\n",
      "\r\n",
      "Barrier statistics:\r\n",
      " Free vars  : 6\r\n",
      " AA' NZ     : 2.100e+01\r\n",
      " Factor NZ  : 2.800e+01\r\n",
      " Factor Ops : 1.400e+02 (less than 1 second per iteration)\r\n",
      " Threads    : 1\r\n",
      "\r\n",
      "                  Objective                Residual\r\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\r\n",
      "   0   2.08088975e+06  1.30260000e+06  8.40e+04 1.54e-03  1.00e+06     0s\r\n",
      "   1   2.51912508e+03  1.29925501e+06  8.40e-02 1.54e-09  1.25e+03     0s\r\n",
      "   2   2.53022010e+03  6.24872767e+03  1.21e-04 2.22e-12  3.58e+00     0s\r\n",
      "   3   4.30701455e+03  4.77310601e+03  4.51e-06 8.24e-14  4.48e-01     0s\r\n",
      "   4   4.31212450e+03  4.35412185e+03  3.36e-07 6.15e-15  4.04e-02     0s\r\n",
      "   5   4.31476546e+03  4.35025443e+03  2.57e-07 4.70e-15  3.41e-02     0s\r\n",
      "   6   4.31884948e+03  4.34238613e+03  1.40e-07 2.66e-15  2.26e-02     0s\r\n",
      "   7   4.32297946e+03  4.33499722e+03  6.53e-08 1.78e-15  1.16e-02     0s\r\n",
      "   8   4.32578871e+03  4.33140802e+03  2.91e-08 1.78e-15  5.40e-03     0s\r\n",
      "   9   4.32693901e+03  4.33038325e+03  1.71e-08 1.78e-15  3.31e-03     0s\r\n",
      "  10   4.32761481e+03  4.32987080e+03  1.04e-08 1.78e-15  2.17e-03     0s\r\n",
      "  11   4.32803919e+03  4.32959075e+03  6.23e-09 1.78e-15  1.49e-03     0s\r\n",
      "  12   4.32834741e+03  4.32939462e+03  3.75e-09 1.78e-15  1.01e-03     0s\r\n",
      "  13   4.32854243e+03  4.32926475e+03  2.25e-09 1.78e-15  6.95e-04     0s\r\n",
      "  14   4.32875741e+03  4.32913701e+03  5.96e-10 1.78e-15  3.65e-04     0s\r\n",
      "  15   4.32895452e+03  4.32897084e+03  3.38e-14 3.55e-15  1.57e-05     0s\r\n",
      "  16   4.32896267e+03  4.32896269e+03  3.38e-14 2.66e-15  1.83e-08     0s\r\n",
      "  17   4.32896268e+03  4.32896268e+03  7.99e-15 2.66e-15  1.84e-11     0s\r\n",
      "\r\n",
      "Barrier solved model in 17 iterations and 0.02 seconds\r\n",
      "Optimal objective 4.32896268e+03\r\n",
      "\r\n",
      "\r\n",
      "User-callback calls 78, time in user-callback 0.00 sec\r\n",
      "Academic license - for non-commercial use only - expires 2022-08-24\r\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\r\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\r\n",
      "Optimize a model with 1 rows, 520 columns and 520 nonzeros\r\n",
      "Model fingerprint: 0xb37c290e\r\n",
      "Model has 135460 quadratic objective terms\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e+00, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  QObjective range [1e-08, 7e+00]\r\n",
      "  Bounds range     [1e+01, 1e+01]\r\n",
      "  RHS range        [0e+00, 0e+00]\r\n",
      "Presolve time: 0.01s\r\n",
      "Presolved: 1 rows, 520 columns, 520 nonzeros\r\n",
      "Presolved model has 135460 quadratic objective terms\r\n",
      "Ordering time: 0.00s\r\n",
      "\r\n",
      "Barrier statistics:\r\n",
      " Free vars  : 3\r\n",
      " AA' NZ     : 6.000e+00\r\n",
      " Factor NZ  : 1.000e+01\r\n",
      " Factor Ops : 3.000e+01 (less than 1 second per iteration)\r\n",
      " Threads    : 1\r\n",
      "\r\n",
      "                  Objective                Residual\r\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\r\n",
      "   0   1.22465487e+06  3.22760000e+06  2.04e+05 2.32e-06  1.00e+06     0s\r\n",
      "   1   4.21729873e+03  3.18545957e+06  6.47e+02 7.36e-09  6.21e+03     0s\r\n",
      "   2  -4.92356958e+04  7.21571408e+05  6.47e-04 5.12e-13  7.41e+02     0s\r\n",
      "   3  -1.25698537e+04  4.09278690e+04  2.47e-05 2.84e-13  5.14e+01     0s\r\n",
      "   4  -1.61231612e+03  5.08726391e+03  5.76e-07 1.03e-13  6.44e+00     0s\r\n",
      "   5  -3.56010790e+02  2.69745265e+03  2.07e-07 4.90e-14  2.94e+00     0s\r\n",
      "   6   4.88821466e-01  2.06782307e+03  1.27e-07 2.85e-14  1.99e+00     0s\r\n",
      "   7   2.42133289e+02  1.61680909e+03  7.71e-08 2.44e-14  1.32e+00     0s\r\n",
      "   8   4.16756576e+02  1.28057572e+03  3.74e-08 1.40e-14  8.31e-01     0s\r\n",
      "   9   5.50481981e+02  1.06929974e+03  1.85e-08 1.06e-14  4.99e-01     0s\r\n",
      "  10   6.12918865e+02  9.85585266e+02  1.17e-08 7.31e-15  3.58e-01     0s\r\n",
      "  11   6.81287750e+02  9.02028660e+02  5.61e-09 7.05e-15  2.12e-01     0s\r\n",
      "  12   7.17165438e+02  8.59328807e+02  3.02e-09 5.93e-15  1.37e-01     0s\r\n",
      "  13   7.46290454e+02  8.27772349e+02  1.43e-09 8.44e-15  7.83e-02     0s\r\n",
      "  14   7.61274468e+02  8.12639382e+02  7.40e-10 4.78e-15  4.94e-02     0s\r\n",
      "  15   7.71828053e+02  8.01780517e+02  3.03e-10 7.61e-15  2.88e-02     0s\r\n",
      "  16   7.79937448e+02  7.93953193e+02  3.55e-14 8.88e-15  1.35e-02     0s\r\n",
      "  17   7.86103811e+02  7.87224496e+02  4.35e-14 6.57e-15  1.08e-03     0s\r\n",
      "  18   7.86665431e+02  7.86670598e+02  3.51e-14 9.45e-15  4.97e-06     0s\r\n",
      "  19   7.86668074e+02  7.86668116e+02  2.49e-12 5.35e-15  4.02e-08     0s\r\n",
      "  20   7.86668087e+02  7.86668088e+02  1.72e-10 7.68e-15  1.40e-09     0s\r\n",
      "\r\n",
      "Barrier solved model in 20 iterations and 0.02 seconds\r\n",
      "Optimal objective 7.86668087e+02\r\n",
      "\r\n",
      "\r\n",
      "User-callback calls 84, time in user-callback 0.00 sec\r\n"
     ]
    }
   ],
   "source": [
    "# Radial Basis Function\n",
    "s = 100\n",
    "K_rbf(x,z) = exp(-(norm(x-z)^2) / (2*(s^2)))\n",
    "# Polynomial Basis Function\n",
    "c = 0; d = 2\n",
    "K_poly(x,z) = (c + dot(x,z))^d\n",
    "\n",
    "C = 10\n",
    "α_rbf = kernel_SVM(X,y,C,K_rbf)\n",
    "α_poly = kernel_SVM(X,y,C,K_poly)\n",
    "\n",
    "# find index of max α component, let that be k \n",
    "k_rbf = argmax(α_rbf)\n",
    "k_poly = argmax(α_poly)\n",
    "\n",
    "b_rbf = y[k_rbf] - sum( α_rbf[i]*y[i]*K_rbf(X[k_rbf,:],X[i,:]) for i = 1:n)\n",
    "b_poly = y[k_poly] - sum( α_poly[i]*y[i]*K_poly(X[k_poly,:],X[i,:]) for i = 1:n)\n",
    "\n",
    "# Prediction function\n",
    "kernel_SVM_classifier(x,K,X,α,b) = sign(sum( α[i]*y[i]*K(x,X[i,:]) for i = 1:size(X,1)) + b);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF kernel: 298 out of 506 training observations misclassified.\n",
      "Polynomial kernel: 284 out of 506 training observations misclassified.\n"
     ]
    }
   ],
   "source": [
    "misclass_rbf = 0\n",
    "misclass_poly = 0\n",
    "for i = 1:n\n",
    "    if kernel_SVM_classifier(X[i,:], K_rbf,X, α_rbf, b_rbf) != y[i]\n",
    "        misclass_rbf += 1\n",
    "    end\n",
    "    if kernel_SVM_classifier(X[i,:], K_poly,X, α_poly, b_poly) != y[i]\n",
    "        misclass_poly += 1\n",
    "    end\n",
    "end\n",
    "println(\"RBF kernel: $misclass_rbf out of $n training observations misclassified.\")\n",
    "println(\"Polynomial kernel: $misclass_poly out of $n training observations misclassified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping Procedure"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bootstrapper(X,y,B)\n",
    "\n",
    "Boostrapping Procedure\n",
    "Returns B bootstrapped samples of input data X and y. Samples are stored in an array. The\n",
    "indices used and not used in each sample are also returned for out-of-bag error calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1 = [3.0 3.0 3.0 3.0 3.0; 4.0 4.0 4.0 4.0 4.0; 3.0 3.0 3.0 3.0 3.0; 2.0 2.0 2.0 2.0 2.0]\n",
      "y_1 = [3.0, 4.0, 3.0, 2.0]\n",
      "Indices used: Set(Any[4, 2, 3])\n",
      "Indices not used: Set([1])\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "X = [ones(5)'; 2*ones(5)'; 3*ones(5)'; 4*ones(5)']\n",
    "y = [1.0; 2.0; 3.0; 4.0]\n",
    "# Number of boostrapped samples\n",
    "B = 10\n",
    "\n",
    "b_samples, ind_used, ind_not_used = bootstrapper(X,y,B)\n",
    "\n",
    "# Observations and indices for the i-th bootstrapped sample\n",
    "i = 1\n",
    "X_b, y_b = b_samples[i]\n",
    "println(\"X_$i = $X_b\\ny_$i = $y_b\")\n",
    "println(\"Indices used: $(ind_used[i])\")\n",
    "println(\"Indices not used: $(ind_not_used[i])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_neural_network(X,y,num_hidden_layers,size_hidden_layers;h,activation,problem_type,num_classes,num_epochs)\n",
    "\n",
    "Initiate Neural Network\n",
    "Computes weight matrices W and biases b and prints the training error. W and b are initialized in this\n",
    "function. Activation options are 'sigmoid' and 'ReLu'. Problem types are 'classification' and 'regression'.\n",
    "Other parameters settings are number of hidden layers, number of neurons per hidden layer, number of epochs,\n",
    "number of classes (1 if regression), and learning rate h."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "update_neural_network(X,y,W,b,num_hidden_layers,size_hidden_layers;h,activation,problem_type,num_classes,num_epochs)\n",
    "\n",
    "Update Neural Network\n",
    "Computes weight matrices W and biases b and prints the training error. W and b are passed as arguments in this\n",
    "function. The network settings should be the same as those passed when creating W and b."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predict_neural_network(X,W,b,num_hidden_layers,size_hidden_layers;activation,problem_type,num_classes)\n",
    "\n",
    "Predictions via Trained Neural Network\n",
    "Computes predictions to input data X given weights W and biases b. Network settings should be the same\n",
    "as those which were used to learn W and b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST handwritten digit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_size = 5000\n",
    "train_x, train_y = MNIST.traindata(1:tr_size)\n",
    "te_size = 200\n",
    "test_x,  test_y  = MNIST.testdata(1:te_size)\n",
    "\n",
    "X = zeros(tr_size,784)\n",
    "for i = 1:tr_size\n",
    "    X[i,:] = reshape(train_x[:,:,i],1,784)\n",
    "end\n",
    "y = train_y[1:tr_size]\n",
    "\n",
    "X_test = zeros(te_size,784)\n",
    "for i = 1:te_size\n",
    "    X_test[i,:] = reshape(test_x[:,:,i],1,784)\n",
    "end\n",
    "y_test = test_y;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n",
      "Total loss is 20236.307355480145.\n",
      "Average loss 4.047261471096029 out of 5000 training images.\n",
      "4507 of 5000 training images misclassified.\n"
     ]
    }
   ],
   "source": [
    "num_hidden_layers = 2\n",
    "size_hidden_layers = 8\n",
    "W,b = train_neural_network(X,y,num_hidden_layers,size_hidden_layers,activation=\"sigmoid\",problem_type=\"classification\",num_classes=10,num_epochs=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n",
      "Total loss is 20236.307355480145.\n",
      "Average loss 4.047261471096029 out of 5000 training images.\n",
      "4507 of 5000 training images misclassified.\n"
     ]
    }
   ],
   "source": [
    "W,b = update_neural_network(X,y,W,b,num_hidden_layers,size_hidden_layers,activation=\"sigmoid\",problem_type=\"classification\",num_classes=10,num_epochs=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_neural_network(X_test,W,b,num_hidden_layers,size_hidden_layers;activation=\"sigmoid\",problem_type=\"classification\",num_classes=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "X_all = transpose(BostonHousing.features())\n",
    "X = X_all[1:450,:]\n",
    "X_test = X_all[451:end,:]\n",
    "y_all = transpose(BostonHousing.targets())\n",
    "y = y_all[1:450]\n",
    "y_test = y_all[451:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n",
      "Average loss 185.63988444260593 out of 450 training images.\n"
     ]
    }
   ],
   "source": [
    "num_hidden_layers = 2\n",
    "size_hidden_layers = 10\n",
    "W,b = train_neural_network(X,y,num_hidden_layers,size_hidden_layers,activation=\"sigmoid\",problem_type=\"regression\",num_epochs=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n",
      "Average loss 185.63959026676432 out of 450 training images.\n"
     ]
    }
   ],
   "source": [
    "W,b = update_neural_network(X,y,W,b,num_hidden_layers,size_hidden_layers,activation=\"sigmoid\",problem_type=\"regression\",num_epochs=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid used.\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_neural_network(X_test,W,b,num_hidden_layers,size_hidden_layers;activation=\"sigmoid\",problem_type=\"regression\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
