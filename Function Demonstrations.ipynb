{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_neural_network"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"./RG_functions.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "X = rand(500,2)\n",
    "y = zeros(500)\n",
    "pos_ind = []\n",
    "neg_ind = []\n",
    "for i=1:size(X,1)\n",
    "    if X[i,2] > 1.5*X[i,1] - .25\n",
    "        y[i] = 1\n",
    "        push!(pos_ind,i)\n",
    "    else\n",
    "        y[i] = 0\n",
    "        push!(neg_ind,i)\n",
    "    end\n",
    "end\n",
    "\n",
    "#class_pos = X[pos_ind,:]\n",
    "#class_neg = X[neg_ind,:]\n",
    "\n",
    "#scatter(class_pos[:,1], class_pos[:,2], color=\"blue\", label=\"Class 1\")\n",
    "#scatter!(class_neg[:,1], class_neg[:,2], color=\"red\", label=\"Class 2\")\n",
    "\n",
    "#x = LinRange(0,1,100)\n",
    "f(x) = 1.5*x - .25\n",
    "#plot!(x, f.(x),xlims=(0,1),ylims=(0,1))\n",
    "\n",
    "x = LinRange(1/5,4/5,10)\n",
    "x_noise_class1 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "x_noise_class2 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "#scatter!(x, x_noise_class1, color=\"blue\")\n",
    "#scatter!(x, x_noise_class2, color=\"red\")\n",
    "Xx = vcat(X,hcat(x,x_noise_class1), hcat(x,x_noise_class2))\n",
    "X = hcat(ones(size(Xx,1),1),Xx)   # append columns of 1's\n",
    "y = vcat(y,ones(10),zeros(10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pred (generic function with 2 methods)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve\n",
    "n,p = size(X)\n",
    "b = zeros(p)\n",
    "b = solve_LR_coef(X,y,b)\n",
    "# Report error\n",
    "prob(x, β) = 1 / (1 + exp(-(dot(x,β) )))\n",
    "\n",
    "# Prediction function\n",
    "pred(x,b) = round(prob(x,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 520 training observations misclassified.\n"
     ]
    }
   ],
   "source": [
    "misclass = 0\n",
    "for i = 1:n\n",
    "    if pred(X[i,:],b) == y[i]\n",
    "        misclass += 1\n",
    "    end\n",
    "end\n",
    "println(\"$misclass out of $n training observations misclassified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())\n",
    "n,p = size(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_kernel_ridge (generic function with 1 method)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Radial Basis Function\n",
    "s = 10\n",
    "K_rbf(x,z) = exp(-(norm(x-z)^2) / (2*(s^2)))\n",
    "# Polynomial\n",
    "c = 1; d = 2\n",
    "K_poly(x,z) = (c + dot(x,z))^d\n",
    "\n",
    "λ = 1\n",
    "α_rbf = kernel_ridge(X,y,λ,K_rbf)\n",
    "α_poly = kernel_ridge(X,y,λ,K_poly)\n",
    "\n",
    "# Prediction function\n",
    "pred_kernel_ridge(x,K,X,α) = sum( K(x,X[i,:]) * α[i] for i = 1:size(X,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error with RBF kernel: 48.58030241248382\n",
      "Mean square error with polynomial kernel: 6.363275739611623\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "y_preds_rbf = zeros(n)\n",
    "y_preds_poly = zeros(n)\n",
    "for i = 1:n\n",
    "    y_preds_rbf[i] = pred_kernel_ridge(X[i,:],K_rbf,X,α_rbf)\n",
    "    y_preds_poly[i] = pred_kernel_ridge(X[i,:],K_poly,X,α_poly)\n",
    "end\n",
    "println(\"Mean square error with RBF kernel: $(Statistics.mean( (y_preds_rbf .- y).^2))\")\n",
    "println(\"Mean square error with polynomial kernel: $(Statistics.mean( (y_preds_poly .- y).^2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximal Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())\n",
    "n,p = size(X)\n",
    "# Center y and estimate β_0\n",
    "y_centered = y .- Statistics.mean(y)\n",
    "β_0 = Statistics.mean(y)\n",
    "# Create matrix of centered X columns\n",
    "X_centered = zeros(n,p)\n",
    "for j in 1:p\n",
    "    X_centered[:,j] = X[:,j] .- Statistics.mean(X[:,j])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1000.\n",
      "Max iterations reached.\n",
      "Real[0; 0.0381765577924749; 0; 0; 0; 0; 0; 0; 0; -0.016327374889328842; 0; 0.010874369828524572; -0.1857394401823319]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pred (generic function with 2 methods)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize β\n",
    "β_init = zeros(size(X_centered,2))\n",
    "λ = 10000\n",
    "\n",
    "β = prox_grad_desc(X_centered, y_centered, β_init, λ)\n",
    "println(\"$β\")\n",
    "\n",
    "# Prediction function\n",
    "pred(X,β,β_0) = β_0 .+ X * β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 74.18408330593503\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred(X,β,β_0)\n",
    "\n",
    "MSE = Statistics.mean((y - y_pred).^2)\n",
    "println(\"Mean squared error: $MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())\n",
    "n,p = size(X)\n",
    "# Center y and estimate β_0\n",
    "y_centered = y .- Statistics.mean(y)\n",
    "β_0 = Statistics.mean(y)\n",
    "# Create matrix of centered X columns\n",
    "X_centered = zeros(n,p)\n",
    "for j in 1:p\n",
    "    X_centered[:,j] = X[:,j] .- Statistics.mean(X[:,j])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 1000.\n",
      "Max iterations reached.\n",
      "Real[-0.041753603120333466; 0.05502475975765802; -0.019075219745038403; 0; 0; 0.015521427968780603; 0.0007620910771608188; -0.009899700036271004; 0.03733115888685481; -0.012845543597233947; -0.04954615426492346; 0.010518427530508552; -0.32525422243992397]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pred (generic function with 2 methods)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize β\n",
    "β_init = zeros(size(X_centered,2))\n",
    "λ = 10000\n",
    "α = 0.1   # 1 means lasso, 0 means ridge\n",
    "\n",
    "β = elastic_net(X_centered, y_centered, β_init, λ, α)\n",
    "println(\"$β\")\n",
    "\n",
    "# Prediction function\n",
    "pred(X,β,β_0) = β_0 .+ X * β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 78.37089939829339\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred(X,β,β_0)\n",
    "\n",
    "MSE = Statistics.mean((y - y_pred).^2)\n",
    "println(\"Mean squared error: $MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Linear) Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear boundary data\n",
    "X = rand(500,2)\n",
    "y = zeros(500)\n",
    "pos_ind = []\n",
    "neg_ind = []\n",
    "for i=1:size(X,1)\n",
    "    if X[i,2] > 1.5*X[i,1] - .25\n",
    "        y[i] = 1\n",
    "        push!(pos_ind,i)\n",
    "    else\n",
    "        y[i] = -1\n",
    "        push!(neg_ind,i)\n",
    "    end\n",
    "end\n",
    "\n",
    "#class_pos = X[pos_ind,:]\n",
    "#class_neg = X[neg_ind,:]\n",
    "\n",
    "#scatter(class_pos[:,1], class_pos[:,2], color=\"blue\", label=\"Class 1\")\n",
    "#scatter!(class_neg[:,1], class_neg[:,2], color=\"red\", label=\"Class 2\")\n",
    "\n",
    "#x = LinRange(0,1,100)\n",
    "f(x) = 1.5*x - .25\n",
    "#plot!(x, f.(x),xlims=(0,1),ylims=(0,1))\n",
    "\n",
    "x = LinRange(1/5,4/5,10)\n",
    "x_noise_class1 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "x_noise_class2 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "#scatter!(x, x_noise_class1, color=\"blue\")\n",
    "#scatter!(x, x_noise_class2, color=\"red\")\n",
    "Xx = vcat(X,hcat(x,x_noise_class1), hcat(x,x_noise_class2))\n",
    "X = hcat(ones(size(Xx,1),1),Xx)   # append columns of 1's\n",
    "y = vcat(y,ones(10),-ones(10));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-08-24\r\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\r\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\r\n",
      "Optimize a model with 521 rows, 524 columns and 3120 nonzeros\r\n",
      "Model fingerprint: 0x345c63d8\r\n",
      "Model has 3 quadratic objective terms\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e-03, 1e+00]\r\n",
      "  Objective range  [0e+00, 0e+00]\r\n",
      "  QObjective range [2e+00, 2e+00]\r\n",
      "  Bounds range     [0e+00, 0e+00]\r\n",
      "  RHS range        [1e+00, 4e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 521 rows, 524 columns, 3120 nonzeros\r\n",
      "Presolved model has 3 quadratic objective terms\r\n",
      "Ordering time: 0.00s\r\n",
      "\r\n",
      "Barrier statistics:\r\n",
      " Dense cols : 4\r\n",
      " Free vars  : 4\r\n",
      " AA' NZ     : 2.600e+03\r\n",
      " Factor NZ  : 3.513e+03\r\n",
      " Factor Ops : 3.024e+04 (less than 1 second per iteration)\r\n",
      " Threads    : 1\r\n",
      "\r\n",
      "                  Objective                Residual\r\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\r\n",
      "   0   7.17216882e-10 -7.17216882e-10  5.20e+05 2.16e-05  9.99e+05     0s\r\n",
      "   1   4.59537013e+06 -4.54358558e+06  1.77e+05 3.39e+02  3.54e+05     0s\r\n",
      "   2   8.53961131e+06 -8.50337042e+06  7.88e+03 1.06e+01  3.10e+04     0s\r\n",
      "   3   2.01043452e+06 -2.01875395e+06  6.49e+02 2.70e-08  5.01e+03     0s\r\n",
      "   4   9.78175175e+05 -1.02267548e+06  3.13e+02 1.30e-08  2.70e+03     0s\r\n",
      "   5   4.34559878e+05 -5.14607629e+05  1.54e+02 6.46e-09  1.42e+03     0s\r\n",
      "   6   8.59320375e+04 -2.70505949e+05  6.67e+01 2.00e-09  7.74e+02     0s\r\n",
      "   7   7.63236889e+04 -2.57256058e+05  6.13e+01 1.85e-09  7.31e+02     0s\r\n",
      "   8   4.45336070e+04 -2.23468637e+05  4.09e+01 1.64e-09  5.35e+02     0s\r\n",
      "   9   2.21400711e+04 -1.84603137e+05  2.21e+01 2.93e-09  3.41e+02     0s\r\n",
      "  10   2.07029194e+04 -1.73116134e+05  2.01e+01 2.83e-09  3.11e+02     0s\r\n",
      "  11   1.88195062e+04 -1.56879711e+05  1.75e+01 2.25e-09  2.72e+02     0s\r\n",
      "  12   1.46907286e+04 -1.33865927e+05  1.26e+01 9.40e-10  2.12e+02     0s\r\n",
      "  13   1.19127575e+04 -1.18739728e+05  9.50e+00 6.41e-10  1.74e+02     0s\r\n",
      "  14   1.02975798e+04 -9.83626307e+04  6.55e+00 4.20e-10  1.37e+02     0s\r\n",
      "  15   7.35547350e+03 -6.29734212e+04  3.05e+00 4.20e-10  7.79e+01     0s\r\n",
      "  16   5.07752166e+03 -2.74567820e+04  7.13e-01 1.55e-09  3.24e+01     0s\r\n",
      "  17   4.45629110e+03 -1.79170070e+04  4.23e-01 9.97e-10  2.20e+01     0s\r\n",
      "  18   3.15969052e+03 -1.17309028e+04  1.92e-01 5.23e-10  1.45e+01     0s\r\n",
      "  19   2.69244841e+03 -8.92366483e+03  1.24e-01 3.47e-10  1.12e+01     0s\r\n",
      "  20   2.45645142e+03 -6.60746216e+03  8.73e-02 2.48e-10  8.76e+00     0s\r\n",
      "  21   1.74392536e+03 -3.78703671e+03  4.24e-02 5.85e-11  5.33e+00     0s\r\n",
      "  22   1.71354780e+03 -2.91002667e+03  3.17e-02 4.77e-11  4.45e+00     0s\r\n",
      "  23   1.40199843e+03 -2.31268589e+03  2.24e-02 3.84e-11  3.58e+00     0s\r\n",
      "  24   1.32868299e+03 -1.90957420e+03  1.77e-02 1.53e-11  3.12e+00     0s\r\n",
      "  25   1.13999765e+03 -1.20783804e+03  1.11e-02 1.06e-11  2.26e+00     0s\r\n",
      "  26   1.15085142e+03 -8.00088943e+02  8.11e-03 5.98e-12  1.88e+00     0s\r\n",
      "  27   9.37334858e+02 -2.59472188e+02  3.86e-03 4.23e-12  1.15e+00     0s\r\n",
      "  28   8.84423642e+02 -7.65799626e+01  3.08e-03 2.98e-12  9.24e-01     0s\r\n",
      "  29   8.35985788e+02 -3.08507351e+01  2.60e-03 3.54e-12  8.34e-01     0s\r\n",
      "  30   8.46634636e+02  5.09065055e+01  2.24e-03 3.06e-12  7.65e-01     0s\r\n",
      "  31   7.36454656e+02  1.58755226e+02  1.32e-03 3.21e-12  5.56e-01     0s\r\n",
      "  32   7.29474408e+02  2.07459892e+02  1.15e-03 2.96e-12  5.02e-01     0s\r\n",
      "  33   6.75697620e+02  3.03501175e+02  6.52e-04 2.34e-12  3.58e-01     0s\r\n",
      "  34   6.33685200e+02  3.30636257e+02  4.65e-04 1.04e-12  2.91e-01     0s\r\n",
      "  35   6.27469188e+02  3.66801703e+02  3.58e-04 7.74e-13  2.51e-01     0s\r\n",
      "  36   5.91481409e+02  3.93028918e+02  1.00e-04 3.98e-13  1.91e-01     0s\r\n",
      "  37   5.68775070e+02  4.31541755e+02  4.85e-05 4.28e-12  1.32e-01     0s\r\n",
      "  38   5.46897457e+02  4.67955410e+02  2.31e-05 6.42e-12  7.59e-02     0s\r\n",
      "  39   5.26324323e+02  4.93151433e+02  5.25e-06 2.09e-12  3.19e-02     0s\r\n",
      "  40   5.24867019e+02  4.96740536e+02  3.90e-06 1.22e-12  2.70e-02     0s\r\n",
      "  41   5.17056856e+02  5.06007755e+02  1.28e-07 2.27e-13  1.06e-02     0s\r\n",
      "  42   5.12179792e+02  5.11370083e+02  1.16e-09 3.56e-12  7.79e-04     0s\r\n",
      "  43   5.11943696e+02  5.11614310e+02  1.97e-10 4.83e-13  3.17e-04     0s\r\n",
      "  44   5.11780338e+02  5.11779996e+02  2.49e-13 8.17e-14  3.28e-07     0s\r\n",
      "  45   5.11780168e+02  5.11780168e+02  9.52e-13 1.28e-13  3.29e-10     0s\r\n",
      "\r\n",
      "Barrier solved model in 45 iterations and 0.01 seconds\r\n",
      "Optimal objective 5.11780168e+02\r\n",
      "\r\n",
      "\r\n",
      "User-callback calls 135, time in user-callback 0.00 sec\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVM_classifier (generic function with 1 method)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameter\n",
    "C = 40\n",
    "# Solve\n",
    "(β_0, β, ξ) = SVM(X,y,C)\n",
    "\n",
    "# Prediction function\n",
    "SVM_classifier(x,β_0,β) = sign(x'*β + β_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 out of 506 training observations misclassified.\n"
     ]
    }
   ],
   "source": [
    "# Report error\n",
    "misclass = 0\n",
    "for i = 1:n\n",
    "    if SVM_classifier(X[i,:], β_0, β) != y[i]\n",
    "        misclass += 1\n",
    "    end\n",
    "end\n",
    "println(\"$misclass out of $n training observations misclassified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic Boundary Data\n",
    "X = rand(500,2)\n",
    "y = zeros(500)\n",
    "pos_ind = []\n",
    "neg_ind = []\n",
    "for i=1:size(X,1)\n",
    "    if X[i,2] > -(X[i,1]+.5)*(X[i,1]-1)\n",
    "        y[i] = 1\n",
    "        push!(pos_ind,i)\n",
    "    else\n",
    "        y[i] = -1\n",
    "        push!(neg_ind,i)\n",
    "    end\n",
    "end\n",
    "\n",
    "#class_pos = X[pos_ind,:]\n",
    "#class_neg = X[neg_ind,:]\n",
    "\n",
    "#scatter(class_pos[:,1], class_pos[:,2], color=\"blue\", label=\"Class 1\")\n",
    "#scatter!(class_neg[:,1], class_neg[:,2], color=\"red\", label=\"Class 2\")\n",
    "\n",
    "#x = LinRange(0,1,100)\n",
    "f(x) = -(x+0.5)*(x-1)\n",
    "#plot!(x, f.(x),xlims=(0,1),ylims=(0,1))\n",
    "\n",
    "x = LinRange(0,1,10)\n",
    "x_noise_class1 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "x_noise_class2 = f.(x) + 1/5 * (rand(10) .- 0.5)\n",
    "#scatter!(x, x_noise_class1, color=\"blue\")\n",
    "#scatter!(x, x_noise_class2, color=\"red\")\n",
    "X = vcat(X,hcat(x,x_noise_class1), hcat(x,x_noise_class2))\n",
    "y = vcat(y,ones(10),-ones(10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-08-24\r\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\r\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\r\n",
      "Optimize a model with 1 rows, 520 columns and 520 nonzeros\r\n",
      "Model fingerprint: 0xc0bf3455\r\n",
      "Model has 135460 quadratic objective terms\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e+00, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  QObjective range [1e+00, 2e+00]\r\n",
      "  Bounds range     [1e+01, 1e+01]\r\n",
      "  RHS range        [0e+00, 0e+00]\r\n",
      "Presolve time: 0.01s\r\n",
      "Presolved: 1 rows, 520 columns, 520 nonzeros\r\n",
      "Presolved model has 135460 quadratic objective terms\r\n",
      "Ordering time: 0.00s\r\n",
      "\r\n",
      "Barrier statistics:\r\n",
      " Free vars  : 6\r\n",
      " AA' NZ     : 2.100e+01\r\n",
      " Factor NZ  : 2.800e+01\r\n",
      " Factor Ops : 1.400e+02 (less than 1 second per iteration)\r\n",
      " Threads    : 1\r\n",
      "\r\n",
      "                  Objective                Residual\r\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\r\n",
      "   0   2.08086560e+06  1.30260000e+06  1.24e+05 1.23e-03  1.00e+06     0s\r\n",
      "   1   2.54651460e+03  1.29915600e+06  6.49e+00 6.44e-08  1.30e+03     0s\r\n",
      "   2   2.44817902e+03  5.86986952e+03  4.80e-03 4.77e-11  3.29e+00     0s\r\n",
      "   3   3.91732746e+03  4.22282879e+03  4.95e-05 4.91e-13  2.94e-01     0s\r\n",
      "   4   3.92275724e+03  3.96632067e+03  5.96e-06 5.92e-14  4.19e-02     0s\r\n",
      "   5   3.92736314e+03  3.95583349e+03  3.38e-06 3.36e-14  2.74e-02     0s\r\n",
      "   6   3.93078324e+03  3.94748633e+03  1.70e-06 1.69e-14  1.61e-02     0s\r\n",
      "   7   3.93367691e+03  3.94187645e+03  7.57e-07 7.51e-15  7.88e-03     0s\r\n",
      "   8   3.93531917e+03  3.93956839e+03  3.77e-07 3.74e-15  4.09e-03     0s\r\n",
      "   9   3.93620196e+03  3.93870132e+03  2.15e-07 2.14e-15  2.40e-03     0s\r\n",
      "  10   3.93658104e+03  3.93832389e+03  1.47e-07 2.66e-15  1.68e-03     0s\r\n",
      "  11   3.93685867e+03  3.93813290e+03  9.86e-08 2.66e-15  1.23e-03     0s\r\n",
      "  12   3.93710117e+03  3.93794126e+03  6.38e-08 1.78e-15  8.08e-04     0s\r\n",
      "  13   3.93723605e+03  3.93784121e+03  4.55e-08 1.78e-15  5.82e-04     0s\r\n",
      "  14   3.93735857e+03  3.93775817e+03  2.95e-08 2.66e-15  3.84e-04     0s\r\n",
      "  15   3.93740399e+03  3.93773324e+03  2.22e-08 2.66e-15  3.17e-04     0s\r\n",
      "  16   3.93748305e+03  3.93768320e+03  1.19e-08 1.78e-15  1.92e-04     0s\r\n",
      "  17   3.93758243e+03  3.93762698e+03  6.51e-10 2.66e-15  4.28e-05     0s\r\n",
      "  18   3.93760532e+03  3.93760629e+03  1.22e-12 2.66e-15  9.27e-07     0s\r\n",
      "  19   3.93760581e+03  3.93760582e+03  3.69e-14 1.78e-15  9.33e-10     0s\r\n",
      "\r\n",
      "Barrier solved model in 19 iterations and 0.02 seconds\r\n",
      "Optimal objective 3.93760581e+03\r\n",
      "\r\n",
      "\r\n",
      "User-callback calls 83, time in user-callback 0.00 sec\r\n",
      "Academic license - for non-commercial use only - expires 2022-08-24\r\n",
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (win64)\r\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\r\n",
      "Optimize a model with 1 rows, 520 columns and 520 nonzeros\r\n",
      "Model fingerprint: 0x1b6b05a1\r\n",
      "Model has 135460 quadratic objective terms\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e+00, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  QObjective range [1e-10, 7e+00]\r\n",
      "  Bounds range     [1e+01, 1e+01]\r\n",
      "  RHS range        [0e+00, 0e+00]\r\n",
      "Warning: Model contains large quadratic objective coefficient range\r\n",
      "         Consider reformulating model or setting NumericFocus parameter\r\n",
      "         to avoid numerical issues.\r\n",
      "Presolve time: 0.01s\r\n",
      "Presolved: 1 rows, 520 columns, 520 nonzeros\r\n",
      "Presolved model has 135460 quadratic objective terms\r\n",
      "Ordering time: 0.00s\r\n",
      "\r\n",
      "Barrier statistics:\r\n",
      " Free vars  : 3\r\n",
      " AA' NZ     : 6.000e+00\r\n",
      " Factor NZ  : 1.000e+01\r\n",
      " Factor Ops : 3.000e+01 (less than 1 second per iteration)\r\n",
      " Threads    : 1\r\n",
      "\r\n",
      "                  Objective                Residual\r\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\r\n",
      "   0   1.44624023e+06  2.50760000e+06  1.43e+05 2.32e-06  1.00e+06     0s\r\n",
      "   1   4.59003585e+03  2.48015391e+06  4.40e+02 7.12e-09  5.44e+03     0s\r\n",
      "   2  -4.97445618e+04  6.64952864e+05  4.40e-04 5.68e-13  6.87e+02     0s\r\n",
      "   3  -1.20973548e+04  5.09767312e+04  2.57e-05 3.13e-13  6.06e+01     0s\r\n",
      "   4  -1.61655478e+03  5.76737584e+03  2.58e-11 9.41e-14  7.10e+00     0s\r\n",
      "   5  -4.10216363e+01  2.42530800e+03  3.80e-12 3.10e-14  2.37e+00     0s\r\n",
      "   6   2.70060142e+02  1.63046972e+03  1.99e-12 1.44e-14  1.31e+00     0s\r\n",
      "   7   4.88374819e+02  1.15513863e+03  8.24e-13 1.19e-14  6.41e-01     0s\r\n",
      "   8   5.90031045e+02  1.02325005e+03  5.06e-13 6.97e-15  4.17e-01     0s\r\n",
      "   9   6.63062812e+02  9.24888988e+02  2.46e-13 8.83e-15  2.52e-01     0s\r\n",
      "  10   6.97487113e+02  8.81693593e+02  1.49e-13 8.52e-15  1.77e-01     0s\r\n",
      "  11   7.29882585e+02  8.45974722e+02  6.48e-14 8.12e-15  1.12e-01     0s\r\n",
      "  12   7.51087514e+02  8.24370314e+02  3.02e-14 6.99e-15  7.05e-02     0s\r\n",
      "  13   7.73003511e+02  8.02111682e+02  1.69e-14 7.00e-15  2.80e-02     0s\r\n",
      "  14   7.82142418e+02  7.93018748e+02  1.29e-14 4.66e-15  1.05e-02     0s\r\n",
      "  15   7.86359674e+02  7.88783328e+02  1.95e-14 8.57e-15  2.33e-03     0s\r\n",
      "  16   7.87415857e+02  7.87738370e+02  2.04e-14 9.37e-15  3.10e-04     0s\r\n",
      "  17   7.87575514e+02  7.87575861e+02  3.55e-14 8.38e-15  3.33e-07     0s\r\n",
      "  18   7.87575667e+02  7.87575705e+02  2.03e-13 6.77e-15  3.68e-08     0s\r\n",
      "  19   7.87575687e+02  7.87575687e+02  2.40e-12 7.23e-15  2.73e-10     0s\r\n",
      "\r\n",
      "Barrier solved model in 19 iterations and 0.02 seconds\r\n",
      "Optimal objective 7.87575687e+02\r\n",
      "\r\n",
      "\r\n",
      "User-callback calls 85, time in user-callback 0.00 sec\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "kernel_SVM_classifier (generic function with 1 method)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Radial Basis Function\n",
    "s = 100\n",
    "K_rbf(x,z) = exp(-(norm(x-z)^2) / (2*(s^2)))\n",
    "# Polynomial\n",
    "c = 0; d = 2\n",
    "K_poly(x,z) = (c + dot(x,z))^d\n",
    "\n",
    "C = 10\n",
    "α_rbf = kernel_SVM(X,y,C,K_rbf)\n",
    "α_poly = kernel_SVM(X,y,C,K_poly)\n",
    "\n",
    "# find index of max α component, let that be k \n",
    "k_rbf = argmax(α_rbf)\n",
    "k_poly = argmax(α_poly)\n",
    "\n",
    "b_rbf = y[k_rbf] - sum( α_rbf[i]*y[i]*K_rbf(X[k_rbf,:],X[i,:]) for i = 1:n)\n",
    "b_poly = y[k_poly] - sum( α_poly[i]*y[i]*K_poly(X[k_poly,:],X[i,:]) for i = 1:n)\n",
    "\n",
    "# Prediction function\n",
    "kernel_SVM_classifier(x,K,X,α,b) = sign(sum( α[i]*y[i]*K(x,X[i,:]) for i = 1:size(X,1)) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF kernel: 318 out of 506 training observations misclassified.\n",
      "Polynomail kernel: 12 out of 506 training observations misclassified.\n"
     ]
    }
   ],
   "source": [
    "misclass_rbf = 0\n",
    "misclass_poly = 0\n",
    "for i = 1:n\n",
    "    if kernel_SVM_classifier(X[i,:], K_rbf,X, α_rbf, b_rbf) != y[i]\n",
    "        misclass_rbf += 1\n",
    "    end\n",
    "    if kernel_SVM_classifier(X[i,:], K_poly,X, α_poly, b_poly) != y[i]\n",
    "        misclass_poly += 1\n",
    "    end\n",
    "end\n",
    "println(\"RBF kernel: $misclass_rbf out of $n training observations misclassified.\")\n",
    "println(\"Polynomail kernel: $misclass_poly out of $n training observations misclassified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ones(5)'; 2*ones(5)'; 3*ones(5)'; 4*ones(5)']\n",
    "y = [1; 2; 3; 4]\n",
    "b_samples, ind_used, ind_not_used = bootstrapper(X,y)\n",
    "X_b, y_b = b_samples[1]\n",
    "X_b\n",
    "y_b\n",
    "ind_used[1]\n",
    "ind_not_used[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classication\n",
    "\n",
    "# load partial training set\n",
    "tr_size = 5000\n",
    "train_x, train_y = MNIST.traindata(1:tr_size)\n",
    "# load partial test set\n",
    "te_size = 200\n",
    "test_x,  test_y  = MNIST.testdata(1:te_size)\n",
    "\n",
    "X = zeros(tr_size,784)\n",
    "for i = 1:tr_size\n",
    "    X[i,:] = reshape(train_x[:,:,i],1,784)\n",
    "end\n",
    "y = train_y[1:tr_size]\n",
    "\n",
    "X_test = zeros(te_size,784)\n",
    "for i = 1:te_size\n",
    "    X_test[i,:] = reshape(test_x[:,:,i],1,784)\n",
    "end\n",
    "y_test = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_layers = 5\n",
    "size_hidden_layers = 100\n",
    "misclass = train_neural_network(X,y,num_hidden_layers,size_hidden_layers,activation=\"sigmoid\",problem_type=\"classification\",num_classes=10,num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "X = transpose(BostonHousing.features())\n",
    "y = transpose(BostonHousing.targets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_layers = 5\n",
    "size_hidden_layers = 100\n",
    "ave_loss = train_neural_network(X,y,num_hidden_layers,size_hidden_layers,activation=\"ReLU\",problem_type=\"regression\",num_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
